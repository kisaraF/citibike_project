{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b26edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from databricks.connect import DatabricksSession\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    DecimalType,\n",
    "    TimestampType,\n",
    ")\n",
    "from pyspark.sql.functions import create_map, lit\n",
    "\n",
    "# Wouldn't need this for the job runtime as it defaults to use SparkSession already\n",
    "# spark = DatabricksSession.builder.serverless().profile(\"fe_kfs\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb19e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To retrieve the parameters at the job run time for metadata\n",
    "\n",
    "pipeline_id = dbutils.widgets.get(\"pipeline_id\")\n",
    "run_id = dbutils.widgets.get(\"run_id\")\n",
    "task_id = dbutils.widgets.get(\"task_id\")\n",
    "processed_timestamp = dbutils.widgets.get(\"processed_timestamp\")\n",
    "catalog = dbutils.widgets.get(\"catalog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc29a86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_schema = StructType(\n",
    "    [\n",
    "        StructField(\"ride_id\", StringType(), True),\n",
    "        StructField(\"rideable_type\", StringType(), True),\n",
    "        StructField(\"started_at\", TimestampType(), True),\n",
    "        StructField(\"ended_at\", TimestampType(), True),\n",
    "        StructField(\"start_station_name\", StringType(), True),\n",
    "        StructField(\"start_station_id\", StringType(), True),\n",
    "        StructField(\"end_station_name\", StringType(), True),\n",
    "        StructField(\"end_station_id\", StringType(), True),\n",
    "        StructField(\"start_lat\", DecimalType(), True),\n",
    "        StructField(\"start_lng\", DecimalType(), True),\n",
    "        StructField(\"end_lat\", DecimalType(), True),\n",
    "        StructField(\"end_lng\", DecimalType(), True),\n",
    "        StructField(\"member_casual\", StringType(), True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af398320",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .options(header=True)\n",
    "    .schema(custom_schema)\n",
    "    .load(\n",
    "        f\"/Volumes/{catalog}/00_landing/source_citibike_data/JC-202503-citibike-tripdata.csv\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9528e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\n",
    "    \"metadata\",\n",
    "    create_map(\n",
    "        lit(\"pipeline_id\"),\n",
    "        lit(pipeline_id),\n",
    "        lit(\"run_id\"),\n",
    "        lit(run_id),\n",
    "        lit(\"task_id\"),\n",
    "        lit(task_id),\n",
    "        lit(\"processed_timestamp\"),\n",
    "        lit(processed_timestamp),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f5c827",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\n",
    "    f\"{catalog}.01_bronze.jc_citibike\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "citibike-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
